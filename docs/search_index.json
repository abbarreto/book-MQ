[["index.html", "Noções básicas de computação quântica Prefácio Sobre mim Objetivos e público-alvo Usando este e-book Agradecimentos", " Noções básicas de computação quântica Adriano B. Barreto1 Instituto Federal do Rio Grande do Sul — Campus Caxias do Sul Última atualização: 23 de outubro de 2022 (histórico de mudanças) Prefácio Este livro é um trabalho em constante progesso. Assim, faltam algumas seções, mas estou constantemente atualizando com correções e preenchendo algumas lacunas. Por causa disto, peço encarecidamente que me informem quando identificarem erros de qualquer espécie (tipo, contas, link quebrado, etc) através do contato de e-mail disponível na nota de rodapé. Sobre mim Sou o Adriano Braga Barreto, professor de física no Campus Caxias do Sul do Instituto Federal do Rio Grande do Sul (IFRS). Tenho doutorado pela Universidade Federal da Paraíba (UFPB), mestrado pela Universidade Federal de Itajubá e licenciatura em física pelo Instituto Federal do Ceará (IFCE). Minha formação tem sido em física teórica, mais especificamente nas áreas de gravitação e cosmologia. Atualmente tenho me interessado pela pesquisa científica na interface Teoria da Relatividade Geral/Mecânica Quântica (RG/MQ), estudo os efeitos relativisticos e gravitacionais em sistemas quânticos, bem como a simulação destes fenômenos em experimentos de Óptica Quântica. Objetivos e público-alvo In this series of lectures you will learn how inherently quantum phenomena, such as quantum interference and quantum entanglement, can make information processing more efficient and more secure, even in the presence of noise. There are many introductions to quantum information science, so it seems like a good idea to start with an explanation of why this particular one exists. When learning such a subject, located somewhere in between mathematics, physics, and computer science, there are many possible approaches, with one main factor being “how far along the informal–formal scale do I want to be?”. In these notes we take the following philosophy: it can be both interesting and fun to cover lots of ground quickly and see as much as possible on a surface level, but it’s also good to know that there is a lot of important stuff that you’ll miss by doing this. In practice, this means that we don’t worry to much about high-level mathematics. That is not to say that we do not use mathematics “properly” — you’ll find a perfectly formal treatment of e.g. quantum channels via completely positive trace-preserving maps in the language of linear algebra — but rather than putting too many footnotes with technical caveats and explanations throughout the main text, we opt to collect them all together into one big “warning” here: The mathematics underlying quantum theory is a vast and in-depth subject, most of which we will never touch upon, some of which we will only allude to, and the rest of which we will cover only in the level of detail necessary to our overarching goal.2 “What”, then, “is the overarching goal?” one might ask. Our answer is this: To help an eager reader understand what quantum information science is all about, and for them to realise which facets of it they would like to study in more detail. But this does not mean that our treatment is cursory! In fact, by the end of this book you will have learnt a fair bit more than what might usually be covered in a standard quantum information science course that you would find in a mathematics masters degree, for example. The interdisciplinary nature of this topic, combined with the diverse backgrounds that different readers have, means that some may find certain chapters easy, while others find the same ones difficult — so if things seem hard to you, then don’t worry: the next chapter might feel much easier! The only real prerequisites are a working knowledge of complex numbers and vectors and matrices; some previous exposure to elementary probability theory and Dirac bra-ket notation (for example) would be helpful, but we provide crash-course introductions to some topics like these at the end of this chapter. A basic knowledge of quantum mechanics (especially in the simple context of finite dimensional state spaces, e.g. state vectors, composite systems, unitary matrices, Born rule for quantum measurements) and some ideas from classical theoretical computer science (complexity theory, algorithms) would be helpful, but is not at all essential. Of course, even if you aren’t familiar with the formal mathematics, then that shouldn’t stop you from reading this book if you want to. You might be surprised at how much you can black box the bits that you don’t understand! The caveat stands, however, that, to really get to grips with this subject, at least some knowledge of maths is necessary — but this is not a bad thing! Finally, throughout this text you will find some technical asides (marked with the icon). These are not at all necessary reading, but are just there to provide the exceptionally eager reader (or perhaps those with a more formal mathematical background) with some extra context, as well as some pointers towards further reading. Usando este e-book This book has some functionality unique to the online (as opposed to the PDF) version, accessed using the toolbar along the top of the window. From left to right, the icons have the following use: — Hide/show the table of contents — Search within the text of the book — Change font size, font face, and toggle dark mode — View the source file of the current chapter on GitHub3 — Open the PDF version of the book in a new tab The online version also has the accompanying lecture videos embedded from YouTube. These videos are hidden by default, but can be shown by clicking on the title next to the icon, wherever one appears. The order of the videos generally differs from that of the written notes, so we have made our best efforts to include them in an order which makes sense relative to the chapters here. For those wishing to really get familiar with this subject, we recommend separately watching the lecture videos following the order in the linked playlist. You will also see the icon in certain places. Clicking on these will display one of the technical asides mentioned in the introduction. If a hyperlink has the icon after it, then it points to a webpage outside this book; otherwise it is an internal link to another section within this book. There are also some keyboard shortcuts: jump between sections with ← and → toggle the table of contents with s open the search bar with f, step through results with Enter, and stop searching with Esc Agradecimentos We thank the following for their helpful comments and corrections: Zhenyu Cai, Jedrzej Burkat, Maryam Khaqan. We also appreciate the work of Yihui Xie in developing the Bookdown package with which this e-book was built. e-mail: adriano.barreto@caxias.ifrs.edu.br↩︎ However, since mathematicians were involved in the writing of this book, we have not been able to resist some digressions here and there.↩︎ The GitHub-savvy of you can use this to create issues pointing out typos, mistakes, etc.↩︎ "],["01-PreliminaresMatematicas.html", "Capítulo 1 Preliminares matemáticas 1.1 Complex numbers 1.2 Euclidean vectors and vector spaces 1.3 Bras and kets 1.4 Daggers 1.5 Geometry 1.6 Operators 1.7 Eigenvalues and eigenvectors 1.8 Outer products 1.9 The trace 1.10 Some useful identities", " Capítulo 1 Preliminares matemáticas Here we quickly recall most of the fundamental mathematical results that we will rely on in the rest of this book, most importantly linear algebra over the complex numbers. However, we will not introduce everything from the ground up. Most notably, we will assume that the reader understands what a matrix is, and how it represents a linear transformation; some prior exposure to complex numbers would be helpful. If an equation like \\(\\operatorname{tr}|a\\rangle\\langle b|=\\langle b|a\\rangle\\) makes sense to you, then you can safely skip over this section and get started directly with Chapter ??. As a small note on notation, we generally write “\\(x\\mathrel{=}y\\)” to mean “\\(x\\) is defined to be (equal to) \\(y\\)”, and “\\(x\\equiv y\\)” to mean “\\(x\\) is just another name for \\(y\\)”, but sometimes we simply just write “\\(x=y\\)”. 1.1 Complex numbers One of the fundamental ingredients of quantum information science (and, indeed, of quantum physics in general) is the notion of complex numbers. It would be disingenuous to expect that a few paragraphs would suffice to make the reader sufficiently familiar with subject, but we try our best here to give a speedy overview of the core principles, and end with some exercises that can be a helpful indicator as to what things you might want to read up on elsewhere. The “classical” way of arriving at complex numbers is as follows: start with the natural numbers \\(\\mathbb{N}=\\{0,1,2,\\ldots\\}\\), which we can add; if we want to be able to invert addition (i.e. subtract), then we end up with the integers \\(\\mathbb{Z}=\\{\\ldots,-2,-1,0,1,2,\\ldots\\}\\), which we can multiply; if we want to be able to invert multiplication (i.e. divide), then we end up with the rationals \\(\\mathbb{Q}=\\{\\frac{p}{q}\\mid p,q\\in\\mathbb{Z}\\}\\). In this process of “closure under more and more binary operations”, we have passed from a monoid, to a group, to a field. Algebraically, then, we seem to be done: we can do all the addition and multiplication that we like, and we can invert it whenever it makes sense to do so (e.g. we can divide, as long as it’s not by \\(0\\)). But there are lots of numbers that turn up in geometry that are not rational, such as \\(\\sqrt{2}\\approx1.414\\), \\(\\pi\\approx3.14\\), and \\(e\\approx2.718\\). To include all of these (and simultaneously make sense of things like infinite sums, and limits), we must do some real analysis — something which we won’t touch upon here — to end up with the real numbers \\(\\mathbb{R}\\). These form a field, just like the rationals, but now we don’t have any “gaps” in our number line. So what’s left to do? Well the reals have one big problem: they are not algebraically closed. That is, there exist polynomials with no roots, i.e. equations of the form \\(a_nx^n+a_{n-1}x^{n-1}+\\ldots+a_1x+a_0=0\\) (where the \\(a_i\\) are real numbers) that have no solutions.4 Somehow the most fundamental such example is the equation \\(x^2+1=0\\), which has no solutions, because the square of any real number must be non-negative, and so \\(\\sqrt{-1}\\not\\in\\mathbb{R}\\). It turns out that if we just throw in this one extra number \\(i\\mathrel{=}\\sqrt{-1}\\) to \\(\\mathbb{R}\\) then we can solve any polynomial — a theorem so important that it’s known as the fundamental theorem of algebra. We call the result of doing this the complex numbers, and denote them by \\(\\mathbb{C}\\). This gives us an algebraic way of understanding what a complex number is: it is a real number \\(x\\) plus an imaginary number \\(iy\\) (where \\(y\\in\\mathbb{R}\\)) That is, every complex number \\(x+iy\\) simply corresponds to a pair of real numbers \\((x,y)\\). So now we can think geometrically! We imagine the complex numbers \\(\\mathbb{C}\\) as the 2-dimensional Euclidean space \\(\\mathbb{R}^2\\), where the \\(x\\)-axis corresponds to the real part of a complex number, and the \\(y\\)-axis to the imaginary part. This really is a geometric way of thinking, since now addition (and subtraction) of complex numbers (which is defined by adding their real and imaginary parts separately) is given by vector addition, as shown in Figure ??. But what about multiplication and division? Following the rules of the game, we can figure out what the product of two complex numbers is by treating the imaginary number \\(i\\) as a “formal variable”, i.e. pretending it’s just a variable in some polynomial, and then remembering that \\(i=\\sqrt{-1}\\) at the very end: \\[ \\begin{aligned} (x+iy)(x&#39;+iy&#39;) &amp;= xx&#39;+ixy&#39;+iyx&#39;+i^2yy&#39; \\\\&amp;= xx&#39;+ixy&#39;+iyx&#39;-yy&#39; \\\\&amp;= xx&#39;-yy&#39;+i(xy&#39;+yx&#39;). \\end{aligned} \\] Division works similarly — the most simple example of inverting a complex number \\(x+iy\\) makes sense whenever \\(x\\) and \\(y\\) are both non-zero, since then we can use the trick of “multiplying by \\(1\\)”: \\[ \\begin{aligned} \\frac{1}{x+iy} &amp;= \\frac{1}{x+iy}\\frac{x-iy}{x-iy} \\\\&amp;= \\frac{x-iy}{x^2+y^2} \\\\&amp;= \\frac{x}{x^2+y^2}-i\\frac{y}{x+2+y^2} \\end{aligned} \\] This other complex number \\(x-iy\\) that we used is somehow special because it is exactly the thing we needed to make the denominator real, so we give it a name: the complex conjugate5 of a complex number \\(z=x+iy\\) is the complex number \\(z^\\star\\mathrel{=}x-iy\\). Geometrically, this is just the reflection of the vector \\((x,y)\\in\\mathbb{R}^2\\) in the \\(x\\)-axis. The product \\(zz^\\star=x^2+y^2\\) is also important: you might recognise (from Pythagoras’ theorem) that \\(\\sqrt{x^2+y^2}\\) is exactly the length of the vector \\((x,y)\\), and so we call the real number \\(|z|\\mathrel{=}\\sqrt{zz^\\star}\\) the modulus (or magnitude, norm, or absolute value). Note then that we can simply write \\(1/z=z^\\star/|z|^2\\). Now things are looking somewhat nice, but the story isn’t complete. We have a good geometric intuition for what a complex number is (a vector in \\(\\mathbb{R}^2\\)) and how to add them (vector addition), as well as what the complex conjugate and the modulus mean (reflection in the \\(x\\)-axis, and the length of the vector, respectively); but what about multiplication and division? To understand these we need to switch from our rectangular coordinates \\(z=x+iy\\) to polar coordinates — instead of describing a point \\(z\\) in \\(\\mathbb{R}^2\\) as “\\(x\\) units left/right and \\(y\\) units up/down”, we describe it as “\\(r\\) units from the origin, at an angle of \\(\\theta\\) radians”. We already know, given \\((x,y)\\in\\mathbb{R}^2\\), how to calculate its distance \\(r\\) from the origin, since this is exactly the length of the vector: \\(r=|(x,y)|=\\sqrt{x^2+y^2}\\). But what about the angle? Some trigonometry tells us that \\(\\theta=\\tan(y/x)\\), so we now know how to convert rectangular to polar coordinates: \\[ x+iy = (x,y) \\longmapsto (r,\\theta) \\mathrel{=}(\\sqrt{x^2+y^2},\\tan(y/x)). \\] It would be nice to know how to go in the other direction though, but this can also be solved with some trigonometry: \\[ (r,\\theta) \\longmapsto (r\\cos\\theta,r\\sin\\theta). \\] Great! … but what’s the point of polar coordinates? Well, it turns out that they give us a geometric way of understanding multiplication: you can show6 that \\((r,\\theta)\\) multiplied by \\((r&#39;,\\theta&#39;)\\) is exactly \\((rr&#39;,\\theta+\\theta&#39;)\\), which says that multiplication by a complex number \\((r,\\theta)\\) is exactly a scaling by a factor of \\(r\\) and a rotation by \\(\\theta\\). This means that we can also easily find the multiplicative inverse of \\((r,\\theta)\\), since it’s just \\((1/r,-\\theta)\\). Finally, complex conjugation just means switching the sign of the angle: \\((r,\\theta)^\\star=(r,-\\theta)\\). There is one last ingredient that we should mention, which is the thing that really solidifies the relation between rectangular and polar coordinates. We know that rectangular coordinates \\((x,y)\\) can be written as \\(x+iy\\), so is there some more algebraic way of writing polar coordinates \\((r,\\theta)\\)? Then we can avoid any ambiguity that might arise from using pairs of numbers — if I tell you that I’m thinking of the complex number \\(z=(0.3,2)\\), do I mean the point \\(0.3+2i\\), or the point that is distance \\(r\\) from the origin at an angle of \\(2\\) radians? Given polar coordinates \\((r,\\theta)\\), we know that this is equal to \\((r\\cos\\theta,r\\sin\\theta)\\) in rectangular coordinates. For simplicity, let’s first consider the case where \\(r=1\\). Then we can write \\((1,\\theta)\\) as \\(\\cos\\theta+i\\sin\\theta\\). Using the Taylor series7 of \\(\\sin\\) and \\(\\cos\\), we can rewrite this as \\[ \\begin{aligned} \\cos\\theta+i\\sin\\theta &amp;= \\left( 1-\\frac{\\theta^2}{2!}+\\frac{\\theta^4}{4!}-\\ldots \\right) + i\\left( \\theta-\\frac{\\theta^3}{3!}+\\frac{\\theta^5}{5!}-\\ldots \\right) \\\\&amp;= 1+i\\theta-\\frac{\\theta^2}{2!}-i\\frac{\\theta^3}{3!}+\\frac{\\theta^4}{4!}+i\\frac{\\theta^5}{5!}-\\ldots \\\\&amp;= 1+i\\theta+\\frac{i^2\\theta^2}{2!}+\\frac{i^3\\theta^3}{3!}+\\frac{i^4\\theta^4}{4!}+\\frac{i^5\\theta^5}{5!}+\\ldots \\\\&amp;= \\exp(i\\theta) \\end{aligned} \\] where at the very end we use the Taylor expansion of the exponential function \\(\\exp(x)=e^x\\). We have just “proved”8 one of the most remarkable formulas in mathematics: Euler’s formula \\[ e^{i\\theta} = \\cos\\theta+i\\sin\\theta \\] (a special case of which gives the famous equation \\(e^{i\\pi}+1=0\\), uniting five fundamental constants: \\(0\\), \\(1\\), \\(i\\), \\(e\\), and \\(\\pi\\)). In summary then, we have two beautiful ways of expressing a complex number \\(z\\in\\mathbb{C}\\), in either its rectangular/planar form or its polar/Euler form: \\[ z = x+iy = re^{i\\theta}. \\] Addition and subtraction are most neatly expressed in the planar form \\(x+iy\\), and multiplication and division are most neatly expressed in the polar form \\(re^{i\\theta}\\); complex conjugation looks nice and tidy in both. We know how to perform addition, multiplication, inversion (which is a special case of division), and complex conjugation on complex numbers in planar form, but we’ve only described how to do the last three of these in polar form: we haven’t said how to write \\(re^{i\\theta}+r&#39;e^{i\\theta&#39;}\\) as \\(se^{i\\varphi}\\) for some \\(s\\) and \\(\\varphi\\). This is because it is very messy looking: \\[ \\begin{aligned} s &amp;= \\sqrt{r^2+(r&#39;)^2+2rr&#39;\\cos(\\theta&#39;-\\theta)} \\\\\\varphi &amp;= \\theta+\\operatorname{atan2}\\big(r&#39;\\sin(\\theta&#39;-\\theta),r+r&#39;\\cos(\\theta&#39;-\\theta)\\big) \\end{aligned} \\] and where \\(\\operatorname{atan2}\\) is the 2-argument arctangent function. You do not need to know everything about this whole story of algebraically closed fields and so on, but it helps to know the basics, so here are some exercises that should help you to become more familiar.9 The set \\(\\mathbb{Q}\\) of rational numbers and the set \\(\\mathbb{R}\\) of real numbers are both fields, but the set \\(\\mathbb{Z}\\) of integers is not. Why not? Look up the formal statement of the fundamental theorem of algebra. Evaluate each of the following quantities: \\[ 1+e^{-i\\pi}, \\quad |1+i|, \\quad (1+i)^{42}, \\quad \\sqrt{i}, \\quad 2^i, \\quad i^i. \\] Here is a simple “proof” that \\(+1=-1\\): \\[ 1=\\sqrt{1}=\\sqrt{(-1)(-1)}=\\sqrt{-1}\\sqrt{-1}=i^2=-1. \\] What is wrong with it? Prove that, for any two complex numbers \\(w,z\\in\\mathbb{C}\\), we always have the inequality \\[ |z-w| \\geqslant|z|-|w|. \\] Hint: use polar form, draw a diagram, and appeal to the triangle inequality! Using the fact that \\(e^{3i\\theta}=(e^{i\\theta})^3\\), derive a formula for \\(\\cos3\\theta\\) in terms of \\(\\cos\\theta\\) and \\(\\sin\\theta\\). 1.2 Euclidean vectors and vector spaces We assume that you are familiar with Euclidean vectors — those arrow-like geometric objects which are used to represent physical quantities, such as trajectories, velocities, or forces. You know that any two velocities can be added to yield a third, and the multiplication of a “velocity vector” by a real number is another “velocity vector”. So a linear combination of vectors is another vector: if \\(v\\) and \\(w\\) are vectors, and \\(\\lambda\\) and \\(\\mu\\) are numbers (rational, real, or complex, for example), then \\(\\lambda v+\\mu w\\) is another vector. Mathematicians have simply taken these properties and defined vectors as anything that we can add and multiply by numbers, as long as everything behaves in a nice enough way. This is basically what an Italian mathematician Giuseppe Peano (1858–1932) did in a chapter of his 1888 book with an impressive title: Calcolo geometrico secondo l’Ausdehnungslehre di H. Grassmann preceduto dalle operazioni della logica deduttiva. Following Peano, we define a vector space as a mathematical structure in which the notion of linear combination “makes sense”. More formally, a complex vector space is a set \\(V\\) such that, given any two vectors \\(a\\) and \\(b\\) (that is, any two elements of \\(V\\)) and any two complex numbers \\(\\alpha\\) and \\(\\beta\\), we can form the linear combination \\(\\alpha a+\\beta b\\), which is also a vector in \\(V\\). There are certain “nice properties” that vector spaces things must satisfy. Addition of vectors must be commutative and associative, with an identity (the zero vector, which is often written as \\(\\mathbf{0}\\)) and an inverse for each \\(v\\) (written as \\(-v\\)). Multiplication by complex numbers must obey the two distributive laws: \\((\\alpha+\\beta)v = \\alpha v+\\beta v\\) and \\(\\alpha (v+w) = \\alpha v+\\alpha w\\). A more succinct way of defining a vector space is as an abelian group endowed with a scalar action of a field. This showcases vector spaces as a particularly well behaved example of a more general object: modules over a ring. A subspace of \\(V\\) is any subset of \\(V\\) which is closed under vector addition and multiplication by complex numbers. Here we start using the Dirac bra-ket notation and write vectors in a somewhat fancy way as \\(|\\text{label}\\rangle\\), where the “label” is anything that serves to specify what the vector is. For example, \\(|\\uparrow\\rangle\\) and \\(|\\downarrow\\rangle\\) may refer to an electron with spin up or down along some prescribed direction, and \\(|0\\rangle\\) and \\(|1\\rangle\\) may describe a quantum bit holding either logical \\(0\\) or \\(1\\). As a maybe more familiar example, the set of binary strings of length \\(n\\) is a vector space over the field \\(\\mathbb{Z}/2\\mathbb{Z}\\) of integers mod \\(2\\); in the case \\(n=2\\) we can write down all the vectors in this vector space in this notation: \\(|00\\rangle\\), \\(|01\\rangle\\), \\(|10\\rangle\\), \\(|11\\rangle\\), where e.g. \\(|10\\rangle+|11\\rangle=|01\\rangle\\) (addition is taken mod \\(2\\)). These are often called ket vectors, or simply kets. (We will deal with “bras” in a moment). A basis in \\(V\\) is a collection of vectors \\(|e_1\\rangle,|e_2\\rangle,\\ldots,|e_n\\rangle\\) such that every vector \\(|v\\rangle\\) in \\(V\\) can be written (in exactly one way) as a linear combination of the basis vectors: \\(|v\\rangle=\\sum_{i=1}^n v_i|e_i\\rangle\\). The number of elements in a basis is called the dimension of \\(V\\).10 The most common, and prototypical, \\(n\\)-dimensional complex vector space (and the space which we will be using most of the time) is the space of ordered \\(n\\)-tuples of complex numbers, usually written as column vectors: \\[ |a\\rangle = \\begin{bmatrix}a_1\\\\a_2\\\\\\vdots\\\\a_n\\end{bmatrix} \\] with a basis given by the column vectors \\(|e_i\\rangle\\) that are \\(0\\) in every row except for a \\(1\\) in the \\(i\\)-th row: \\[ |e_1\\rangle = \\begin{bmatrix}1\\\\0\\\\\\vdots\\\\0\\end{bmatrix} \\qquad |e_2\\rangle = \\begin{bmatrix}0\\\\1\\\\\\vdots\\\\0\\end{bmatrix} \\qquad\\ldots\\qquad |e_n\\rangle = \\begin{bmatrix}0\\\\0\\\\\\vdots\\\\1\\end{bmatrix} \\] and where addition of vectors is done component-wise, so that \\[ \\left(\\sum_{i=1}^n v_i|e_i\\rangle\\right)+\\left(\\sum_{i=1}^n w_i|e_i\\rangle\\right) = \\sum_{i=1}^n (v_i+w_i)|e_i\\rangle \\] or, in column vectors, \\[ \\begin{gathered} |v\\rangle = \\begin{bmatrix}v_1\\\\v_2\\\\\\vdots\\\\v_n\\end{bmatrix} \\qquad |w\\rangle = \\begin{bmatrix}w_1\\\\w_2\\\\\\vdots\\\\w_n\\end{bmatrix} \\\\\\alpha|a\\rangle+\\beta|b\\rangle = \\begin{bmatrix}\\alpha v_1+\\beta w_1\\\\\\alpha v_2+\\beta w_2\\\\\\vdots\\\\\\alpha v_n+\\beta w_n\\end{bmatrix} \\end{gathered} \\] Throughout the course we will deal only with vector spaces of finite dimensions. This is sufficient for all our purposes and we will avoid many mathematical subtleties associated with infinite dimensional spaces, for which we would need the tools of functional analysis. Formally, whenever we say \\(n\\)-dimensional Euclidean space, we mean the real vector space \\(\\mathbb{R}^n\\). 1.3 Bras and kets An inner product on a vector space \\(V\\) (over the complex numbers) is a function that assigns to each pair of vectors \\(|u\\rangle,|v\\rangle\\in V\\) a complex number \\(\\langle u|v\\rangle\\), and satisfies the following conditions: \\(\\langle u|v\\rangle=\\langle v|u\\rangle^\\star\\) \\(\\langle v|v\\rangle\\geqslant 0\\) for all \\(|v\\rangle\\) \\(\\langle v|v\\rangle= 0\\) if and only if \\(|v\\rangle=0\\) where \\({}^\\star\\) denotes complex conjugation (sometimes written as \\(z\\mapsto\\bar{z}\\) instead). The inner product must also be linear in the second argument but antilinear in the first argument: \\[ \\langle c_1u_1+c_2u_2|v\\rangle = c_1^\\star\\langle u_1|v\\rangle+c_2^\\star\\langle u_2|v\\rangle \\] for any complex constants \\(c_1\\) and \\(c_2\\). To any physical system we associate11 a complex vector space with an inner product, known as a Hilbert space \\(\\mathcal{H}\\). The inner product between vectors \\(|u\\rangle\\) and \\(|v\\rangle\\) in \\({\\mathcal{H}}\\) is written as \\(\\langle u|v\\rangle\\). If \\(V\\) is a vector space with an inner product \\(\\langle-,-\\rangle\\), then this gives us a norm on \\(V\\) by defining \\(\\|x\\|=\\sqrt{\\langle x,x\\rangle}\\) and thus a metric by defining \\(d(x,y)=\\|y-x\\|\\). We say that a sequence \\((x_n)\\) in \\(V\\) is Cauchy if its elements “eventually always get closer”, i.e. if for all \\(\\varepsilon&gt;0\\) there exists some \\(N\\in\\mathbb{N}\\) such that for all \\(m,n&gt;N\\) we have \\(\\|x_n-x_m\\|&lt;\\varepsilon\\). We say that a normed space is complete if every Cauchy sequence converges in that space, i.e. if the limits of sequences that should exist actually do exist. Now one useful fact is the following: on a finite dimensional vector space, all norms are equivalent. (Note that this does not mean that \\(\\|x\\|_1=\\|x\\|_2\\) for any two norms \\(\\|-\\|_1\\) and \\(\\|-\\|_2\\), but simply that they “induce the same topology” — feel free to look up the precise definition elsewhere). This follows from another useful fact: in a finite dimensional vector space, the unit ball is compact. By a short topological argument, we can use these facts to show that what we claimed, namely that every finite dimensional inner product space is complete (with respect to the norm induced by the inner product, and thus with respect to any norm, since all norms are equivalent). In the infinite dimensional case these facts are not true, and we have a special name for those inner product spaces which are complete: Hilbert spaces. So working in the finite dimensional case means that “we do not have to worry about analysis”, in that the completeness property comes for free the moment we have an inner product, and we can freely refer to inner product spaces as Hilbert spaces. For example, for column vectors \\(|u\\rangle\\) and \\(|v\\rangle\\) in \\(\\mathbb{C}^n\\) written as \\[ |u\\rangle = \\begin{bmatrix}u_1\\\\u_2\\\\\\vdots\\\\u_n\\end{bmatrix} \\qquad |v\\rangle = \\begin{bmatrix}v_1\\\\v_2\\\\\\vdots\\\\v_n\\end{bmatrix} \\] their inner product is defined by \\[ \\langle u|v\\rangle = u_1^\\star v_1 + u_2^\\star v_2+\\ldots + u_n^\\star v_n. \\] Following Dirac, we may split the inner product into two ingredients: \\[ \\langle u|v\\rangle \\longrightarrow \\langle u|\\,|v\\rangle. \\] Here \\(|v\\rangle\\) is a ket vector, and \\(\\langle u|\\) is called a bra vector, or a bra, and can be represented by a row vector: \\[ \\langle u| = \\begin{bmatrix}u_1^\\star,&amp;u_2^\\star,&amp;\\ldots,&amp;u_n^\\star\\end{bmatrix}. \\] The inner product can now be viewed as the result of the matrix multiplication: \\[ \\begin{aligned} \\langle u|v\\rangle &amp;= \\begin{bmatrix}u_1^\\star,&amp;u_2^\\star,&amp;\\ldots,&amp;u_n^\\star\\end{bmatrix} \\cdot \\begin{bmatrix}v_1\\\\v_2\\\\\\vdots\\\\v_n\\end{bmatrix} \\\\&amp;= u_1^\\star v_1 + u_2^\\star v_2 + \\ldots + u_n^\\star v_n. \\end{aligned} \\] Bras are vectors: you can add them, and multiply them by scalars (which, here, are complex numbers), but they are vectors in the space \\({\\mathcal{H}}^\\star\\) which is dual to \\(\\mathcal{H}\\). Elements of \\({\\mathcal{H}}^\\star\\) are linear functionals, that is, linear maps from \\(\\mathcal{H}\\) to \\(\\mathbb{C}\\). A linear functional \\(\\langle u|\\) acting on a vector \\(|v\\rangle\\) in \\(\\mathcal{H}\\) gives a complex number \\(\\langle u|v\\rangle\\). All Hilbert spaces of the same (finite) dimension are isomorphic, so the differences between quantum systems cannot be really understood without additional structure. This structure is provided by a specific algebra of operators acting on \\(\\mathcal{H}\\). 1.4 Daggers Although \\(\\mathcal{H}\\) and \\(\\mathcal{H}^\\star\\) are not identical spaces — the former is inhabited by kets, and the latter by bras — they are closely related. There is a bijective map from one to the other given by \\(|v\\rangle\\leftrightarrow \\langle v|\\), and denoted by a dagger:12 \\[ \\begin{aligned} \\langle v| &amp;= (|v\\rangle)^\\dagger \\\\|v\\rangle &amp;= (\\langle v|)^\\dagger. \\end{aligned} \\] We usually omit the parentheses when it is obvious what the dagger operation applies to. The dagger operation, also known as Hermitian conjugation, is antilinear: \\[ \\begin{aligned} (c_1|v_1\\rangle+c_2|v_2\\rangle)^\\dagger &amp;= c_1^\\star\\langle v_1| + c_2^\\star\\langle v_2| \\\\(c_1\\langle v_1|+c_2\\langle v_2|)^\\dagger &amp;= c_1^\\star|v_1\\rangle + c_2^\\star|v_2\\rangle. \\end{aligned} \\] Also, when applied twice, the dagger operation is the identity map. You might already be familiar with Hermitian conjugation under another name: the conjugate transpose13 of an \\((n\\times m)\\) matrix \\(A\\) is an \\((m\\times n)\\) matrix \\(A^\\dagger\\), obtained by interchanging the rows and columns of \\(A\\) and taking complex conjugates of each entry in \\(A\\), i.e. \\(A^\\dagger_{ij}=A^\\star_{ji}\\). In particular then, \\[ |v\\rangle = \\begin{bmatrix}v_1\\\\v_2\\\\\\vdots\\\\v_n\\end{bmatrix} \\overset{\\dagger}{\\longleftrightarrow} \\langle v| = \\begin{bmatrix}v_1^\\star,&amp;v_2^\\star,&amp;\\ldots,&amp;v_n^\\star\\end{bmatrix}. \\] 1.5 Geometry The inner product brings geometry: the length, or norm, of \\(|v\\rangle\\) is given by \\(\\|v\\|=\\sqrt{\\langle v|v\\rangle}\\), and we say that \\(|u\\rangle\\) and \\(|v\\rangle\\) are orthogonal if \\(\\langle u|v\\rangle=0\\). Any maximal set of pairwise orthogonal vectors of unit length14 forms an orthonormal basis, and so any vector can be expressed as a linear combination of the basis vectors: \\[ \\begin{gathered} |v\\rangle =\\sum_i v_i|e_i\\rangle \\\\\\text{where $v_i=\\langle e_i|v\\rangle$}. \\end{gathered} \\] Then the bras \\(\\langle e_i|\\) form the dual basis \\[ \\begin{gathered} \\langle v| =\\sum_i v_i^\\star\\langle e_i| \\\\\\text{where $v_i^\\star=\\langle v|e_i\\rangle$}. \\end{gathered} \\] To make the notation a bit less cumbersome, we will sometimes label the basis kets as \\(|i\\rangle\\) rather than \\(|e_i\\rangle\\), and write \\[ \\begin{aligned} |v\\rangle &amp;= \\sum_i |i\\rangle\\langle i|v\\rangle \\\\\\langle v| &amp;= \\sum_j \\langle v|i\\rangle\\langle i| \\end{aligned} \\] but do not confuse \\(|0\\rangle\\) with the zero vector! We never write the zero vector as \\(|0\\rangle\\), but only ever as \\(0\\), without any bra or ket decorations (so e.g. \\(|v\\rangle+0=|v\\rangle\\)). Now that we have some notion of geometry, we can explain a bit more about this idea of associating a Hilbert space to a quantum system — we will use some terminology that we have not yet introduced, but all will be explained in due time. To any isolated quantum system, which can be prepared in \\(n\\) perfectly distinguishable states, we can associate a Hilbert space \\(\\mathcal{H}\\) of dimension \\(n\\) such that each vector \\(|v\\rangle\\in\\mathcal{H}\\) of unit length \\(\\langle v|v\\rangle=1\\) represents a quantum state of the system. The overall phase of the vector has no physical significance: \\(|v\\rangle\\) and \\(e^{i\\varphi}|v\\rangle\\) (for any real \\(\\varphi\\)) both describe the same state. We note here one more fact that also won’t yet make sense, but which won’t hurt to have hidden away in the back of your mind. The inner product \\(\\langle u|v\\rangle\\) is the probability amplitude that a quantum system prepared in state \\(|v\\rangle\\) will be found in state \\(|u\\rangle\\) upon measurement. This means that states corresponding to orthogonal vectors (i.e. \\(\\langle u|v\\rangle=0\\)) are perfectly distinguishable: if we prepare the system in state \\(|v\\rangle\\), then it will never be found in state \\(|u\\rangle\\), and vice versa. 1.6 Operators A linear map between two vector spaces \\(\\mathcal{H}\\) and \\(\\mathcal{K}\\) is a function \\(A\\colon\\mathcal{H}\\to\\mathcal{K}\\) that respects linear combinations: \\[ A(c_1|v_1\\rangle+c_2|v_2\\rangle)=c_1 A|v_1\\rangle+c_2 A|v_2\\rangle \\] for any vectors \\(|v_1\\rangle,|v_2\\rangle\\) and any complex numbers \\(c_1,c_2\\). We will focus mostly on endomorphisms, that is, maps from \\(\\mathcal{H}\\) to \\(\\mathcal{H}\\), and we will call them operators. The symbol \\(\\mathbf{1}\\) is reserved for the identity operator that maps every element of \\(\\mathcal{H}\\) to itself (i.e. \\(\\mathbf{1}|v\\rangle=|v\\rangle\\) for all \\(|v\\rangle\\in\\mathcal{H}\\)). The product \\(BA\\) of two operators \\(A\\) and \\(B\\) is the operator obtained by first applying \\(A\\) to some ket \\(|v\\rangle\\) and then \\(B\\) to the ket which results from applying \\(A\\): \\[ (BA)|v\\rangle = B(A|v\\rangle). \\] The order does matter: in general, \\(BA\\neq AB\\). In the exceptional case in which \\(AB=BA\\), one says that these two operators commute. The inverse of \\(A\\), written as \\(A^{-1}\\), is the operator that satisfies \\(AA^{-1}=\\mathbf{1}=A^{-1}A\\). For finite-dimensional spaces, one only needs to check one of these two conditions, since any one of the two implies the other, whereas, on an infinite-dimensional space, both must be checked. Finally, given a particular basis, an operator \\(A\\) is uniquely determined by the entries of its matrix: \\(A_{ij}=\\langle i|A|j\\rangle\\). The adjoint, or Hermitian conjugate, of an linear map \\(A\\), denoted by \\(A^\\dagger\\), is defined by the relation \\[ \\begin{gathered} \\langle i|A^\\dagger|j\\rangle = \\langle j|A|i\\rangle^\\star \\\\\\text{for all $|i\\rangle,|j\\rangle\\in\\mathcal{H}$} \\end{gathered} \\] and \\(\\dagger\\) turns \\((n\\times m)\\) matrices into \\((m\\times n)\\) matrices. An operator \\(A\\) is said to be normal if \\(AA^\\dagger = A^\\dagger A\\) unitary if \\(A^\\dagger=A^{-1}\\) Hermitian (or self-adjoint) if \\(A^\\dagger = A\\). In particular then, being unitary implies being normal, since if \\(A^\\dagger=A^{-1}\\) then \\(AA^\\dagger=A^\\dagger A\\), since both of these are equal to \\(\\mathbf{1}\\). Note also that unitary and Hermitian operators must be operators, i.e. they are represented by an \\((n\\times n)\\) matrix. Any physically admissible evolution of an isolated quantum system is represented by a unitary operator.15 Note that unitary operators preserve the inner product: given a unitary operator \\(U\\) and two kets \\(|a\\rangle\\) and \\(|b\\rangle\\), and defining \\(|a&#39;\\rangle=U|a\\rangle\\) and \\(|b&#39;\\rangle=U|b\\rangle\\), we have that \\[ \\begin{gathered} \\langle a&#39;|=\\langle a|U^\\dagger \\\\\\langle b&#39;|=\\langle b|U^\\dagger \\\\\\langle a&#39;|b&#39;\\rangle=\\langle a|U^\\dagger U|b\\rangle=\\langle a|\\mathbf{1}|b\\rangle=\\langle a|b\\rangle. \\end{gathered} \\] Preserving the inner product implies preserving the norm induced by this product, i.e. unit state vectors are mapped to unit state vectors, i.e. unitary operations are the isometries of the Euclidean norm. 1.7 Eigenvalues and eigenvectors Given an operator \\(A\\), an eigenvector is a non-zero vector \\(|v\\rangle\\) such that \\[ A|v\\rangle = \\lambda|v\\rangle \\] for some \\(\\lambda\\in\\mathbb{C}\\) (which is called the corresponding eigenvalue). We call the pair \\((\\lambda,|v\\rangle)\\) an eigenpair, and we call the set of eigenvalues the spectrum of \\(A\\), denoted by \\(\\sigma(A)\\). It is a surprising (but incredibly useful) fact that every operator has at least one eigenpair.16 Geometrically, an eigenvector of an operator \\(A\\) is a vector upon which \\(A\\) simply acts by “stretching”. Rewriting the defining property of an eigenpair \\((\\lambda,|v\\rangle)\\), we see that \\[ (A-\\lambda\\mathbf{1})|v\\rangle = 0 \\] which tells us that the operator \\(A-\\lambda\\mathbf{1}\\) has a non-zero kernel, and is thus non-invertible. This gives a useful characterisation of the spectrum in terms of a determinant: \\[ \\sigma(A) = \\{\\lambda\\in\\mathbb{C} \\mid \\det(A-\\lambda\\mathbf{1})=0\\}. \\] 1.8 Outer products Apart from the inner product \\(\\langle u|v\\rangle\\), which is a complex number, we can also form the outer product \\(|u\\rangle\\langle v|\\), which is a linear map (operator) on \\(\\mathcal{H}\\) (or on \\(\\mathcal{H}^\\star\\), depending how you look at it). This is what physicists like (and what mathematicians dislike!) about Dirac notation: a certain degree of healthy ambiguity. The result of \\(|u\\rangle\\langle v|\\) acting on a ket \\(|x\\rangle\\) is \\(|u\\rangle\\langle v|x\\rangle\\), i.e. the vector \\(|u\\rangle\\) multiplied by the complex number \\(\\langle v|x\\rangle\\). Similarly, the result of \\(|u\\rangle\\langle v|\\) acting on a bra \\(\\langle y|\\) is \\(\\langle y|u\\rangle\\langle v|\\), i.e. the linear functional \\(\\langle v|\\) multiplied by the complex number \\(\\langle y|u\\rangle\\). The product of two maps, \\(A=|a\\rangle\\langle b|\\) followed by \\(B=|c\\rangle\\langle d|\\), is a linear map \\(BA\\), which can be written in Dirac notation as \\[ BA = |c\\rangle\\langle d|a\\rangle\\langle b| = \\langle d|a\\rangle|c\\rangle\\langle b| \\] i.e. the inner product (complex number) \\(\\langle d|a\\rangle\\) times the outer product (linear map) \\(|c\\rangle\\langle b|\\). Any operator on \\(\\mathcal{H}\\) can be expressed as a sum of outer products. Given an orthonormal basis \\(\\{|e_i\\rangle\\}_{i=1,\\ldots,n}\\), any operator which maps the basis vectors \\(|e_i\\rangle\\) to vectors \\(|f_i\\rangle\\) can be written as \\(\\sum_{i=1}^n|f_i\\rangle\\langle e_i|\\). If the vectors \\(\\{|f_i\\rangle\\}\\) also form an orthonormal basis then the operator simply “rotates” one orthonormal basis into another. These are unitary operators which preserve the inner product. In particular, if each \\(|e_i\\rangle\\) is mapped to \\(|e_i\\rangle\\), then we obtain the identity operator: \\[ \\sum_i|e_i\\rangle\\langle e_i|=\\mathbf{1}. \\] This relation holds for any orthonormal basis, and it is one of the most ubiquitous and useful formulas in quantum theory, known as completeness.17 For example, for any vector \\(|v\\rangle\\) and for any orthonormal basis \\(\\{|e_i\\rangle\\}\\), we have \\[ \\begin{aligned} |v\\rangle &amp;= \\mathbf{1}|v\\rangle \\\\&amp;= \\sum_i |e_i\\rangle\\langle e_i|\\;|v\\rangle \\\\&amp;= \\sum_i |e_i\\rangle\\;\\langle e_i|v\\rangle \\\\&amp;= \\sum_i v_i|e_i\\rangle \\end{aligned} \\] where \\(v_i=\\langle e_i|v\\rangle\\) are the components of \\(|v\\rangle\\). Finally, note that calculating the adjoint of an outer product boils down to just swapping the order: \\[ (|a\\rangle\\langle b|)^\\dagger = |b\\rangle\\langle a|. \\] This whole package of stuff and properties and structure (i.e. finite dimensional Hilbert spaces with linear maps and the dagger) bundles up into an abstract framework called a dagger compact category. We will not delve into the vast world of category theory in this book, and to reach an understanding of all the ingredients that go into the one single definition of dagger compact categories would take more than a single chapter. But it’s a good idea to be aware that there are researchers in quantum information science who work entirely from this approach, known as categorical quantum mechanics. 1.9 The trace The trace is an operation which turns outer products into inner products, \\[ \\operatorname{tr}\\colon |b\\rangle\\langle a| \\longmapsto \\langle a|b\\rangle. \\] We have just seen that any linear operator can be written as a sum of outer products, and so we can extend the definition of trace (by linearity) to any operator. Equivalently, for any square matrix \\(A\\), the trace of \\(A\\) can be defined to be the sum of its diagonal elements: \\[ \\operatorname{tr}A = \\sum_k \\langle e_k|A|e_k\\rangle = \\sum_k A_{kk}. \\] In fact, the trace of \\(A\\) is equal to the sum of the eigenvalues of \\(A\\), even in the case where \\(A\\) is not diagonalisable. You can show, using this definition or otherwise, that the trace is cyclic18 (\\(\\operatorname{tr}(AB) = \\operatorname{tr}(BA)\\)) and linear (\\(\\operatorname{tr}(\\alpha A+\\beta B) = \\alpha\\operatorname{tr}(A)+\\beta\\operatorname{tr}(B)\\), where \\(A\\) and \\(B\\) are square matrices and \\(\\alpha\\) and \\(\\beta\\) complex numbers). To recover the first definition from the second, we argue as follows: \\[ \\begin{aligned} \\operatorname{tr}|b\\rangle\\langle a| &amp;= \\sum_k \\langle e_k|b\\rangle\\langle a|e_k\\rangle \\\\&amp;= \\sum_k \\langle a|e_k\\rangle\\langle e_k|b\\rangle \\\\&amp;= \\langle a|\\mathbf{1}|b\\rangle \\\\&amp;= \\langle a|b\\rangle. \\end{aligned} \\] Here, the second term can be viewed both as the sum of the diagonal elements of \\(|b\\rangle\\langle a|\\) in the \\(|e_k\\rangle\\) basis, and as the sum of the products of two complex numbers \\(\\langle e_k|b\\rangle\\) and \\(\\langle a|e_k\\rangle\\). We have used the decomposition of the identity, \\(\\sum_k|e_k\\rangle\\langle e_k|=\\mathbf{1}\\). Given that we can decompose the identity by choosing any orthonormal basis, it is clear that the trace does not depend on the choice of the basis. 1.10 Some useful identities Here is a summary of some particularly useful equalities concerning bras, kets, inner products, outer products, traces, and operators, that we will be using time and time again. In all of these, \\(|a\\rangle,|b\\rangle\\in\\mathcal{H}\\) are kets, \\(A,B,C\\) are operators on \\(\\mathcal{H}\\), and \\(\\alpha,\\beta\\in\\mathbb{C}\\) are scalars. Dagger for bras and kets: \\(|a\\rangle^\\dagger = \\langle a|\\) \\(\\langle a|^\\dagger = |a\\rangle\\) \\((|a\\rangle\\langle b|)^\\dagger = |b\\rangle\\langle a|\\) \\((\\alpha|a\\rangle+\\beta|b\\rangle)^\\dagger = \\alpha^\\star\\langle a|+\\beta^\\star\\langle b|\\) Dagger for operators: \\((AB)^\\dagger = B^\\dagger A^\\dagger\\) \\((A^\\dagger)^\\dagger = A\\) \\((\\alpha A+\\beta B)^\\dagger = \\alpha^\\star A^\\dagger+\\beta^\\star B^\\dagger\\) Trace: \\(\\operatorname{tr}(\\alpha A+\\beta B) = \\alpha \\operatorname{tr}(A)+\\beta\\operatorname{tr}(B)\\) \\(\\operatorname{tr}(ABC) = \\operatorname{tr}(CAB) = \\operatorname{tr}(BCA)\\) \\(\\operatorname{tr}|a\\rangle\\langle b| = \\langle b|a\\rangle\\) \\(\\operatorname{tr}(A|a\\rangle\\langle b|) = \\langle b|A|a\\rangle = \\operatorname{tr}(|a\\rangle\\langle b|A)\\) To explain why we care so much about polynomials would be the subject of a whole nother book, but one important reason (of the many!), for both analysts and geometers alike, is the Weierstrass Approximation Theorem.↩︎ The more common notation in mathematics is \\(\\bar{z}\\) instead of \\(z^\\star\\), but physicists tend to like the latter.↩︎ Exercise. Prove this!↩︎ If you don’t know about Taylor series, then feel free to just skim this part, but make sure to read the punchline!↩︎ It is very important to point out that this “proof” is not rigorous or formal — you need to be very very careful when rearranging infinite sums! However, this proof can be made rigorous by using some real analysis.↩︎ Note that we have not really given you enough information in this section to be able to solve all these exercises, but that is intentional! Sometimes we like to ask questions and not answer them, with the hope that you will enjoy getting to do some research by yourself.↩︎ Showing that this definition is independent of the basis that we choose is a “fun” linear algebra exercise.↩︎ The question of how exactly we construct this associated space is a subtle one in the case of arbitrary physical systems, but we shall see that this is relatively straightforward when working with the types of systems that we consider in this book.↩︎ “Is this a \\(\\dagger\\) which I see before me…”↩︎ In mathematics texts this operation is often denoted by \\({}^\\star\\) rather than \\({}^\\dagger\\), but we reserve the former for complex conjugation without matrix transposition. Note, however, that scalars can be thought of as \\((1\\times1)\\) matrices, and in this special case we have that \\(\\dagger=\\star\\).↩︎ That is, consider sets of vectors \\(|e_i\\rangle\\) such that \\(\\langle e_i|e_j\\rangle=\\delta_{ij}\\) (where the Kronecker delta \\(\\delta_{ij}\\) is \\(0\\) if \\(i\\neq j\\), and \\(1\\) if \\(i=j\\).), and then pick any of the largest such sets (which must exist, since we assume our vector spaces to be finite dimensional).↩︎ This is an axiom, justified by experimental evidence, and also by some sort of mathematical intuition. So, in this book, we take this as a fact that we do not question. It is, however, very interesting to question it: why should we assume this to be true?↩︎ You can prove this for an \\((n\\times n)\\) matrix \\(A\\) by considering the set \\(\\{|v\\rangle,A|v\\rangle,A^2|v\\rangle,\\ldots,A^n|v\\rangle\\}\\) of vectors in \\(\\mathbb{C}^n\\). Since this has \\(n+1\\) elements, it must be linearly dependent, and so (after some lengthy algebra) we can construct an eigenpair.↩︎ Not to be confused with “completeness” in the sense of Hilbert spaces.↩︎ Note that “cyclic” does not mean the same thing as “permutation invariant”! It is not true in general that \\(\\operatorname{tr}(ABC)=\\operatorname{tr}(CBA)\\), but only that \\(\\operatorname{tr}(ABC)=\\operatorname{tr}(BCA)=\\operatorname{tr}(CAB)\\), i.e. we can only cyclically permute the operators.↩︎ "],["02-cross-refs.html", "Capítulo 2 Cross-references 2.1 Chapters and sub-chapters 2.2 Captioned figures and tables", " Capítulo 2 Cross-references Cross-references make it easier for your readers to find and link to elements in your book. 2.1 Chapters and sub-chapters There are two steps to cross-reference any heading: Label the heading: # Hello world {#nice-label}. Leave the label off if you like the automated heading generated based on your heading title: for example, # Hello world = # Hello world {#hello-world}. To label an un-numbered heading, use: # Hello world {-#nice-label} or {# Hello world .unnumbered}. Next, reference the labeled heading anywhere in the text using \\@ref(nice-label); for example, please see Chapter 2. If you prefer text as the link instead of a numbered reference use: any text you want can go here. 2.2 Captioned figures and tables Figures and tables with captions can also be cross-referenced from elsewhere in your book using \\@ref(fig:chunk-label) and \\@ref(tab:chunk-label), respectively. See Figure 2.1. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 2.1: Here is a nice figure! Don’t miss Table 2.1. knitr::kable( head(pressure, 10), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 2.1: Here is a nice table! temperature pressure 0 0.0002 20 0.0012 40 0.0060 60 0.0300 80 0.0900 100 0.2700 120 0.7500 140 1.8500 160 4.2000 180 8.8000 "],["02-DinamicaParticulas.html", "Capítulo 3 Dinâmica de partículas 3.1 A section", " Capítulo 3 Dinâmica de partículas All chapters start with a first-level heading followed by your chapter title, like the line above. There should be only one first-level heading (#) per .Rmd file. 3.1 A section All chapter sections start with a second-level (##) or higher heading followed by your section title, like the sections above and below here. You can have as many as you want within a chapter. An unnumbered section Chapters and sections are numbered by default. To un-number a heading, add a {.unnumbered} or the shorter {-} at the end of the heading, like in this section. "],["03-parts.html", "Capítulo 4 Parts", " Capítulo 4 Parts You can add parts to organize one or more book chapters together. Parts can be inserted at the top of an .Rmd file, before the first-level chapter heading in that same file. Add a numbered part: # (PART) Act one {-} (followed by # A chapter) Add an unnumbered part: # (PART\\*) Act one {-} (followed by # A chapter) Add an appendix as a special kind of un-numbered part: # (APPENDIX) Other stuff {-} (followed by # A chapter). Chapters in an appendix are prepended with letters instead of numbers. "],["03-TeoriaOndulatoria.html", "Capítulo 5 Teoria ondulatória 5.1 A section", " Capítulo 5 Teoria ondulatória All chapters start with a first-level heading followed by your chapter title, like the line above. There should be only one first-level heading (#) per .Rmd file. 5.1 A section All chapter sections start with a second-level (##) or higher heading followed by your section title, like the sections above and below here. You can have as many as you want within a chapter. An unnumbered section Chapters and sections are numbered by default. To un-number a heading, add a {.unnumbered} or the shorter {-} at the end of the heading, like in this section. "],["04-citations.html", "Capítulo 6 Footnotes and citations 6.1 Footnotes 6.2 Citations", " Capítulo 6 Footnotes and citations 6.1 Footnotes Footnotes are put inside the square brackets after a caret ^[]. Like this one 19. 6.2 Citations Reference items in your bibliography file(s) using @key. For example, we are using the bookdown package (Xie 2022) (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and knitr (Xie 2015) (this citation was added manually in an external file book.bib). Note that the .bib files need to be listed in the index.Rmd with the YAML bibliography key. The RStudio Visual Markdown Editor can also make it easier to insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations Teste de citação Laforest (2015), Zubairy (2020), Perry et al. (2019), Canabarro et al. (2022) Referências "],["04-FundamentosMQ.html", "Capítulo 7 Fundamentos da mecânica quântica", " Capítulo 7 Fundamentos da mecânica quântica "],["05-blocks.html", "Capítulo 8 Blocks 8.1 Equations 8.2 Theorems and proofs 8.3 Callout blocks", " Capítulo 8 Blocks 8.1 Equations Here is an equation. \\[\\begin{equation} f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k} \\tag{8.1} \\end{equation}\\] You may refer to using \\@ref(eq:binom), like see Equation (8.1). 8.2 Theorems and proofs Labeled theorems can be referenced in text using \\@ref(thm:tri), for example, check out this smart theorem 8.1. Theorem 8.1 For a right triangle, if \\(c\\) denotes the length of the hypotenuse and \\(a\\) and \\(b\\) denote the lengths of the other two sides, we have \\[a^2 + b^2 = c^2\\] Read more here https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html. 8.3 Callout blocks The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html "],["06-share.html", "Capítulo 9 Sharing your book 9.1 Publishing 9.2 404 pages 9.3 Metadata for sharing", " Capítulo 9 Sharing your book 9.1 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html 9.2 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you’d like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. 9.3 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your book’s title and description are also used. This gitbook uses the same social sharing data across all chapters in your book- all links shared will look the same. Specify your book’s source repository on GitHub using the edit key under the configuration options in the _output.yml file, which allows users to suggest an edit by linking to a chapter’s source file. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/gitbook.html Or use: ?bookdown::gitbook "],["07-references.html", "Referências", " Referências "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
